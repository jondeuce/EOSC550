{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Character based RNN language model trained on 'The Complete Works of William Shakespeare'\n",
    "Based on http://karpathy.github.io/2015/05/21/rnn-effectiveness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNNTYPE = :lstm\n",
    "BATCHSIZE = 256\n",
    "SEQLENGTH = 100\n",
    "INPUTSIZE = 168\n",
    "VOCABSIZE = 84\n",
    "HIDDENSIZE = 334\n",
    "NUMLAYERS = 1\n",
    "DROPOUT = 0.0\n",
    "LR=0.001\n",
    "BETA_1=0.9\n",
    "BETA_2=0.999\n",
    "EPS=1e-08\n",
    "EPOCHS = 30;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"4925284-element Array{UInt8,1}\", \"525665-element Array{UInt8,1}\", \"84-element Array{Char,1}\")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load 'The Complete Works of William Shakespeare'\n",
    "using Knet\n",
    "include(Knet.dir(\"data\",\"gutenberg.jl\"))\n",
    "trn,tst,chars = shakespeare()\n",
    "map(summary,(trn,tst,chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Cheated of feature by dissembling nature,\r\n",
      "    Deform'd, unfinish'd, sent before my time\r\n",
      "    Into this breathing world scarce half made up,\r\n",
      "    And that so lamely and unfashionable\r\n",
      "   \n"
     ]
    }
   ],
   "source": [
    "# Print a sample\n",
    "println(string(chars[trn[1020:1210]]...)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(192, 20)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Minibatch data\n",
    "function mb(a)\n",
    "    N = div(length(a),BATCHSIZE)\n",
    "    x = reshape(a[1:N*BATCHSIZE],N,BATCHSIZE)' # reshape full data to (B,N) with contiguous rows\n",
    "    minibatch(x[:,1:N-1], x[:,2:N], SEQLENGTH) # split into (B,T) blocks \n",
    "end\n",
    "dtrn,dtst = mb(trn),mb(tst)\n",
    "map(length, (dtrn,dtst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "function initmodel()\n",
    "    w(d...)=KnetArray(xavier(Float32,d...))\n",
    "    b(d...)=KnetArray(zeros(Float32,d...))\n",
    "    r,wr = rnninit(INPUTSIZE,HIDDENSIZE,rnnType=RNNTYPE,numLayers=NUMLAYERS,dropout=DROPOUT)\n",
    "    wx = w(INPUTSIZE,VOCABSIZE)\n",
    "    wy = w(VOCABSIZE,HIDDENSIZE)\n",
    "    by = b(VOCABSIZE,1)\n",
    "    return r,wr,wx,wy,by\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss and its gradient\n",
    "function predict(ws,xs,hx,cx)\n",
    "    r,wr,wx,wy,by = ws\n",
    "    x = wx[:,xs]                                    # xs=(B,T) x=(X,B,T)\n",
    "    x = dropout(x,DROPOUT)\n",
    "    y,hy,cy = rnnforw(r,wr,x,hx,cx,hy=true,cy=true) # y=(H,B,T) hy=cy=(H,B,L)\n",
    "    y = dropout(y,DROPOUT)\n",
    "    y2 = reshape(y,size(y,1),size(y,2)*size(y,3))   # y2=(H,B*T)\n",
    "    return wy*y2.+by, hy, cy\n",
    "end\n",
    "\n",
    "function loss(w,x,y,h)\n",
    "    py,hy,cy = predict(w,x,h...)\n",
    "    h[1],h[2] = getval(hy),getval(cy)\n",
    "    return nll(py,y)\n",
    "end\n",
    "\n",
    "lossgradient = gradloss(loss);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and test loops\n",
    "function train(model,data,optim)\n",
    "    hiddens = Any[nothing,nothing]\n",
    "    Σ,N=0,0\n",
    "    for (x,y) in data\n",
    "        grads,loss1 = lossgradient(model,x,y,hiddens)\n",
    "        update!(model, grads, optim)\n",
    "        Σ,N=Σ+loss1,N+1\n",
    "    end\n",
    "    return Σ/N\n",
    "end\n",
    "\n",
    "function test(model,data)\n",
    "    hiddens = Any[nothing,nothing]\n",
    "    Σ,N=0,0\n",
    "    for (x,y) in data\n",
    "        Σ,N = Σ+loss(model,x,y,hiddens), N+1\n",
    "    end\n",
    "    return Σ/N\n",
    "end; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model=optim=nothing; knetgc()\n",
    "model = initmodel()\n",
    "optim = optimizers(model, Adam; lr=LR, beta1=BETA_1, beta2=BETA_2, eps=EPS);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mTraining...\n",
      "\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 17.228594 seconds (243.32 k allocations: 131.754 MiB, 0.05% gc time)\n",
      "  0.713869 seconds (208.56 k allocations: 19.673 MiB, 0.50% gc time)\n",
      "(:epoch, 1, :trnppl, 13.917706f0, :tstppl, 7.7539396f0)\n",
      " 17.002396 seconds (237.14 k allocations: 131.419 MiB, 0.07% gc time)\n",
      "  0.540640 seconds (4.39 k allocations: 8.980 MiB)\n",
      "(:epoch, 2, :trnppl, 6.683613f0, :tstppl, 6.022151f0)\n",
      " 17.100168 seconds (238.03 k allocations: 131.432 MiB, 0.04% gc time)\n",
      "  0.548066 seconds (8.03 k allocations: 9.035 MiB, 0.17% gc time)\n",
      "(:epoch, 3, :trnppl, 5.5206413f0, :tstppl, 5.272025f0)\n",
      " 17.164160 seconds (239.27 k allocations: 131.452 MiB, 0.04% gc time)\n",
      "  0.553129 seconds (4.39 k allocations: 8.980 MiB)\n",
      "(:epoch, 4, :trnppl, 4.927807f0, :tstppl, 4.8367276f0)\n",
      " 17.201483 seconds (239.04 k allocations: 131.448 MiB, 0.03% gc time)\n",
      "  0.551327 seconds (7.71 k allocations: 9.030 MiB, 0.15% gc time)\n",
      "(:epoch, 5, :trnppl, 4.5414467f0, :tstppl, 4.532178f0)\n",
      " 17.227623 seconds (239.63 k allocations: 131.457 MiB, 0.03% gc time)\n",
      "  0.551735 seconds (4.39 k allocations: 8.980 MiB)\n",
      "(:epoch, 6, :trnppl, 4.261379f0, :tstppl, 4.293539f0)\n",
      " 17.247081 seconds (239.05 k allocations: 131.448 MiB, 0.04% gc time)\n",
      "  0.548589 seconds (4.39 k allocations: 8.980 MiB)\n",
      "(:epoch, 7, :trnppl, 4.055349f0, :tstppl, 4.1123657f0)\n",
      " 17.238229 seconds (238.99 k allocations: 131.447 MiB, 0.03% gc time)\n",
      "  0.550816 seconds (8.23 k allocations: 9.038 MiB, 0.15% gc time)\n",
      "(:epoch, 8, :trnppl, 3.8986566f0, :tstppl, 3.975367f0)\n",
      " 17.249896 seconds (239.10 k allocations: 131.449 MiB, 0.03% gc time)\n",
      "  0.549032 seconds (4.39 k allocations: 8.980 MiB)\n",
      "(:epoch, 9, :trnppl, 3.7771063f0, :tstppl, 3.8722267f0)\n",
      " 17.254530 seconds (239.05 k allocations: 131.448 MiB, 0.03% gc time)\n",
      "  0.550300 seconds (7.84 k allocations: 9.032 MiB, 0.38% gc time)\n",
      "(:epoch, 10, :trnppl, 3.6797094f0, :tstppl, 3.7880776f0)\n",
      " 17.246807 seconds (239.51 k allocations: 131.455 MiB, 0.03% gc time)\n",
      "  0.550743 seconds (4.39 k allocations: 8.980 MiB)\n",
      "(:epoch, 11, :trnppl, 3.5989754f0, :tstppl, 3.7221966f0)\n",
      " 17.219345 seconds (238.99 k allocations: 131.447 MiB, 0.03% gc time)\n",
      "  0.549712 seconds (7.51 k allocations: 9.027 MiB, 0.15% gc time)\n",
      "(:epoch, 12, :trnppl, 3.5297894f0, :tstppl, 3.6709332f0)\n",
      " 17.273543 seconds (239.83 k allocations: 131.460 MiB, 0.03% gc time)\n",
      "  0.552455 seconds (4.39 k allocations: 8.980 MiB)\n",
      "(:epoch, 13, :trnppl, 3.4733021f0, :tstppl, 3.620203f0)\n",
      " 17.240213 seconds (239.05 k allocations: 131.448 MiB, 0.04% gc time)\n",
      "  0.550801 seconds (4.39 k allocations: 8.980 MiB)\n",
      "(:epoch, 14, :trnppl, 3.4263494f0, :tstppl, 3.581685f0)\n",
      " 17.254331 seconds (239.05 k allocations: 131.448 MiB, 0.03% gc time)\n",
      "  0.551070 seconds (7.96 k allocations: 9.034 MiB, 0.14% gc time)\n",
      "(:epoch, 15, :trnppl, 3.382556f0, :tstppl, 3.547529f0)\n",
      " 17.254557 seconds (239.30 k allocations: 131.452 MiB, 0.03% gc time)\n",
      "  0.550567 seconds (4.39 k allocations: 8.980 MiB)\n",
      "(:epoch, 16, :trnppl, 3.3460147f0, :tstppl, 3.5223541f0)\n",
      " 17.256538 seconds (239.05 k allocations: 131.448 MiB, 0.03% gc time)\n",
      "  0.548974 seconds (7.65 k allocations: 9.029 MiB, 0.14% gc time)\n",
      "(:epoch, 17, :trnppl, 3.3121345f0, :tstppl, 3.50173f0)\n",
      " 17.267594 seconds (239.71 k allocations: 131.458 MiB, 0.03% gc time)\n",
      "  0.549768 seconds (4.39 k allocations: 8.980 MiB)\n",
      "(:epoch, 18, :trnppl, 3.2834446f0, :tstppl, 3.4792671f0)\n",
      " 17.277053 seconds (239.05 k allocations: 131.448 MiB, 0.03% gc time)\n",
      "  0.550533 seconds (4.39 k allocations: 8.980 MiB)\n",
      "(:epoch, 19, :trnppl, 3.2564921f0, :tstppl, 3.4628859f0)\n",
      " 17.225015 seconds (238.99 k allocations: 131.447 MiB, 0.03% gc time)\n",
      "  0.549126 seconds (8.17 k allocations: 9.037 MiB, 0.16% gc time)\n",
      "(:epoch, 20, :trnppl, 3.234047f0, :tstppl, 3.4473507f0)\n",
      " 17.231960 seconds (239.19 k allocations: 131.450 MiB, 0.03% gc time)\n",
      "  0.551239 seconds (4.39 k allocations: 8.980 MiB)\n",
      "(:epoch, 21, :trnppl, 3.210488f0, :tstppl, 3.4329898f0)\n",
      " 17.226244 seconds (239.04 k allocations: 131.448 MiB, 0.03% gc time)\n",
      "  0.551314 seconds (7.78 k allocations: 9.031 MiB, 0.14% gc time)\n",
      "(:epoch, 22, :trnppl, 3.190849f0, :tstppl, 3.4202354f0)\n",
      " 17.246562 seconds (239.57 k allocations: 131.456 MiB, 0.03% gc time)\n",
      "  0.550203 seconds (4.39 k allocations: 8.980 MiB)\n",
      "(:epoch, 23, :trnppl, 3.1708825f0, :tstppl, 3.4091263f0)\n",
      " 17.204943 seconds (239.05 k allocations: 131.448 MiB, 0.03% gc time)\n",
      "  0.551898 seconds (4.39 k allocations: 8.980 MiB)\n",
      "(:epoch, 24, :trnppl, 3.1530654f0, :tstppl, 3.3975418f0)\n",
      " 17.251291 seconds (238.99 k allocations: 131.447 MiB, 0.03% gc time)\n",
      "  0.547031 seconds (8.29 k allocations: 9.039 MiB, 0.16% gc time)\n",
      "(:epoch, 25, :trnppl, 3.1373825f0, :tstppl, 3.3851924f0)\n",
      " 17.236001 seconds (239.04 k allocations: 131.448 MiB, 0.03% gc time)\n",
      "  0.549253 seconds (4.39 k allocations: 8.980 MiB)\n",
      "(:epoch, 26, :trnppl, 3.121747f0, :tstppl, 3.3817685f0)\n",
      " 17.253746 seconds (239.05 k allocations: 131.448 MiB, 0.03% gc time)\n",
      "  0.547647 seconds (7.91 k allocations: 9.033 MiB, 0.15% gc time)\n",
      "(:epoch, 27, :trnppl, 3.1071384f0, :tstppl, 3.3748627f0)\n",
      " 17.229659 seconds (239.44 k allocations: 131.454 MiB, 0.03% gc time)\n",
      "  0.550442 seconds (4.39 k allocations: 8.980 MiB)\n",
      "(:epoch, 28, :trnppl, 3.093008f0, :tstppl, 3.3634353f0)\n",
      " 17.252012 seconds (238.99 k allocations: 131.447 MiB, 0.03% gc time)\n",
      "  0.552565 seconds (7.57 k allocations: 9.028 MiB, 0.16% gc time)\n",
      "(:epoch, 29, :trnppl, 3.080998f0, :tstppl, 3.3526473f0)\n",
      " 17.237079 seconds (239.76 k allocations: 131.459 MiB, 0.03% gc time)\n",
      "  0.549277 seconds (4.39 k allocations: 8.980 MiB)\n",
      "(:epoch, 30, :trnppl, 3.0681787f0, :tstppl, 3.350249f0)\n",
      "533.660206 seconds (7.69 M allocations: 4.132 GiB, 0.03% gc time)\n"
     ]
    }
   ],
   "source": [
    "info(\"Training...\")\n",
    "@time for epoch in 1:EPOCHS\n",
    "    @time trnloss = train(model,dtrn,optim) # ~18 seconds\n",
    "    @time tstloss = test(model,dtst)        # ~0.5 seconds\n",
    "    println((:epoch, epoch, :trnppl, exp(trnloss), :tstppl, exp(tstloss)))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".         Carch if he came 'To those fixed;\n",
      "     'Tis his father from the battle craved bestow and o'ertend.\n",
      "        Not cold hunt, where they wounds:\n",
      "      [The Pedrailded]\n",
      "\n",
      "                   Enter Mar of them, and Attendanigona challensaugh\n",
      "\n",
      "ACT BIOPEDRWAV. Yes. You are not still-to fall aboard\n",
      "    And, like likes when knock your mind. Fie!\n",
      "    SERVAND shadardy the gods should she grow hends invocheth.\n",
      "    There's an emples doubt not anything. Here he,\n",
      "    Satisfactorous, are here. In the fessal\n",
      "    That become yet and tarally.\n",
      "    Peace, sirrah, he would not call me.\n",
      "    Forbid wife; but know of yourselves,\n",
      "    Old the shorts for the fed.   I think he in mine\n",
      "    hundred fastic perfume.\n",
      "  COMINIUS. Your varinade, perform thieves so living;\n",
      "    Foretell, thence, and on my I look'n, oath,\n",
      "    Yet it hath told not sly to your vexs!\n",
      "    You are no peace fall that, knows; and live and infuring\n",
      "    May till I speak with a hand, defend the danger:\n",
      "    Or else the moo\n"
     ]
    }
   ],
   "source": [
    "# Sample from trained model\n",
    "function generate(model,n)\n",
    "    function sample(y)\n",
    "        p,r=Array(exp.(y-logsumexp(y))),rand()\n",
    "        for j=1:length(p); (r -= p[j]) < 0 && return j; end\n",
    "    end\n",
    "    h,c = nothing,nothing\n",
    "    x = findfirst(chars,'\\n')\n",
    "    for i=1:n\n",
    "        y,h,c = predict(model,[x],h,c)\n",
    "        x = sample(y)\n",
    "        print(chars[x])\n",
    "    end\n",
    "    println()\n",
    "end\n",
    "\n",
    "generate(model,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.1",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
