{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that this is an instructional example written in low-level Julia/Knet and it is slow to train.\n",
    "# For a faster and high-level implementation please see `@doc rnninit` and `@doc rnnforw`.\n",
    "\n",
    "using Knet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A one layer MLP vs a simple RNN\n",
    "\n",
    "([Elman 1990](http://onlinelibrary.wiley.com/doi/10.1207/s15516709cog1402_1/pdf)) A simple RNN takes the previous hidden state as an extra input, and returns the next hidden state as an extra output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/RNN-rolled.png\" width=\"150\" />\n",
    "([image source](http://colah.github.io/posts/2015-08-Understanding-LSTMs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison of a single hidden layer MLP and corresponding RNN\n",
    "\n",
    "function mlp1(param, input)\n",
    "    hidden = tanh(input * param[1] .+ param[2])\n",
    "    output = hidden * param[3] .+ param[4]\n",
    "    return output\n",
    "end\n",
    "\n",
    "function rnn1(param, input, hidden)\n",
    "    input2 = hcat(input, hidden)\n",
    "    hidden = tanh(input2 * param[1] .+ param[2])\n",
    "    output = hidden * param[3] .+ param[4]\n",
    "    return (hidden, output)\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backpropagation through time (BPTT)\n",
    "\n",
    "([Werbos, 1988](http://www.sciencedirect.com/science/article/pii/089360808890007X))\n",
    "An RNN unrolled in time is similar to a deep feed-forward network which (i) has as many layers as time steps, (ii) has weights shared between different layers, and (iii) may have multiple inputs and outputs received and produced at individual layers. Backpropagation can be used to train RNNs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/RNN-unrolled.png\" width=800 />\n",
    "([image source](http://colah.github.io/posts/2015-08-Understanding-LSTMs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss calculation and training.\n",
    "\n",
    "function rnnloss(param,inputs,hidden,outputs)\n",
    "    # inputs and outputs are sequences of the same length\n",
    "    sumloss = 0\n",
    "    for t in 1:length(inputs)\n",
    "        output,hidden = rnn1(param,inputs[t],hidden)\n",
    "        sumloss += loss_function(output,outputs[t])\n",
    "    end\n",
    "    return sumloss\n",
    "end\n",
    "\n",
    "rnngrad = grad(rnnloss);\n",
    "\n",
    "# ... train with our usual SGD procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Long Short-Term Memory (LSTM)\n",
    "([Hochreiter and Schmidhuber, 1997](https://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf))\n",
    "LSTM is a more sophisticated RNN module that performs better with long-range dependencies. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-chain.png\" width=800 />\n",
    "([image source](http://colah.github.io/posts/2015-08-Understanding-LSTMs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{align}\n",
    "f_t &= \\sigma(W_f\\cdot[h_{t-1},x_t] + b_f) & \\text{forget gate} \\\\\n",
    "i_t &= \\sigma(W_i\\cdot[h_{t-1},x_t] + b_i) & \\text{input gate} \\\\\n",
    "\\tilde{C}_t &= \\tanh(W_C\\cdot[h_{t-1},x_t] + b_C) & \\text{cell candidate} \\\\\n",
    "C_t &= f_t \\ast C_{t-1} + i_t \\ast \\tilde{C}_t & \\text{new cell} \\\\\n",
    "o_t &= \\sigma(W_o\\cdot[h_{t-1},x_t] + b_o) & \\text{output gate} \\\\\n",
    "h_t &= o_t \\ast \\tanh(C_t) & \\text{new output}\\\\\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A LSTM implementation in Knet\n",
    "\n",
    "function lstm(param, state, input)\n",
    "    weight,bias = param\n",
    "    hidden,cell = state\n",
    "    h       = size(hidden,2)\n",
    "    gates   = hcat(input,hidden) * weight .+ bias\n",
    "    forget  = sigm.(gates[:,1:h])\n",
    "    ingate  = sigm.(gates[:,1+h:2h])\n",
    "    outgate = sigm.(gates[:,1+2h:3h])\n",
    "    change  = tanh.(gates[:,1+3h:4h])\n",
    "    cell    = cell .* forget + ingate .* change\n",
    "    hidden  = outgate .* tanh.(cell)\n",
    "    return (hidden,cell)\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence to sequence model (S2S)\n",
    "([Sutskever et al. 2014](https://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf))\n",
    "S2S models learn to map input sequences to output sequences using an encoder and a decoder RNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://nzw0301.github.io/images/seq2seq.svg\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S2S loss function and its gradient\n",
    "\n",
    "function s2s(model, inputs, outputs)\n",
    "    state = initstate(inputs[1], model[:state0])\n",
    "    for input in inputs\n",
    "        input = onehotrows(input, model[:embed1])\n",
    "        input = input * model[:embed1]\n",
    "        state = lstm(model[:encode], state, input)\n",
    "    end\n",
    "    EOS = eosmatrix(outputs[1], model[:embed2])\n",
    "    input = EOS * model[:embed2]\n",
    "    sumlogp = 0\n",
    "    for output in outputs\n",
    "        state = lstm(model[:decode], state, input)\n",
    "        ypred = predict(model[:output], state[1])\n",
    "        ygold = onehotrows(output, model[:embed2])\n",
    "        sumlogp += sum(ygold .* logp(ypred,2))\n",
    "        input = ygold * model[:embed2]\n",
    "    end\n",
    "    state = lstm(model[:decode], state, input)\n",
    "    ypred = predict(model[:output], state[1])\n",
    "    sumlogp += sum(EOS .* logp(ypred,2))\n",
    "    return -sumlogp\n",
    "end\n",
    "\n",
    "s2sgrad = gradloss(s2s);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://docs.google.com/drawings/d/1BR871g8k4jpI-mKeXiJfpY5Jl5cKcognvH7hHSugQds/pub?w=958&h=236\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S2S model definition\n",
    "\n",
    "function initmodel(H, V; atype=(gpu()>=0 ? KnetArray{Float32} : Array{Float32}))\n",
    "    init(d...)=atype(xavier(d...))\n",
    "    model = Dict{Symbol,Any}()\n",
    "    model[:state0] = [ init(1,H), init(1,H) ]\n",
    "    model[:embed1] = init(V,H)\n",
    "    model[:encode] = [ init(2H,4H), init(1,4H) ]\n",
    "    model[:embed2] = init(V,H)\n",
    "    model[:decode] = [ init(2H,4H), init(1,4H) ]\n",
    "    model[:output] = [ init(H,V), init(1,V) ]\n",
    "    return model\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S2S helper functions\n",
    "\n",
    "function predict(param, input)\n",
    "    input * param[1] .+ param[2]\n",
    "end\n",
    "\n",
    "function initstate(idx, state0)\n",
    "    h,c = state0\n",
    "    h = h .+ fill!(similar(AutoGrad.getval(h), length(idx), length(h)), 0)\n",
    "    c = c .+ fill!(similar(AutoGrad.getval(c), length(idx), length(c)), 0)\n",
    "    return (h,c)\n",
    "end\n",
    "\n",
    "function onehotrows(idx, embeddings)\n",
    "    nrows,ncols = length(idx), size(embeddings,1)\n",
    "    z = zeros(Float32,nrows,ncols)\n",
    "    @inbounds for i=1:nrows\n",
    "        z[i,idx[i]] = 1\n",
    "    end\n",
    "    oftype(AutoGrad.getval(embeddings),z)\n",
    "end\n",
    "\n",
    "let EOS=nothing; global eosmatrix\n",
    "function eosmatrix(idx, embeddings)\n",
    "    nrows,ncols = length(idx), size(embeddings,1)\n",
    "    if EOS==nothing || size(EOS) != (nrows,ncols)\n",
    "        EOS = zeros(Float32,nrows,ncols)\n",
    "        EOS[:,1] = 1\n",
    "        EOS = oftype(getval(embeddings), EOS)\n",
    "    end\n",
    "    return EOS\n",
    "end\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "479828-element Array{Array{Int64,1},1}\n",
      "479828-element Array{SubString{String},1}\n",
      "70-element Array{Char,1}\n",
      "Dict{Char,Int64} with 70 entries\n",
      "Abencerrages\n",
      "abend\n",
      "abends\n",
      "Abenezra\n",
      "abenteric\n"
     ]
    }
   ],
   "source": [
    "# Use reversing English words as an example task\n",
    "# This loads them from /usr/share/dict/words and converts each character to an int.\n",
    "\n",
    "function readdata(file=\"/usr/share/dict/words\")\n",
    "    global strings = map(chomp,readlines(file))\n",
    "    global tok2int = Dict{Char,Int}()\n",
    "    global int2tok = Vector{Char}()\n",
    "    push!(int2tok,'\\n'); tok2int['\\n']=1 # We use '\\n'=>1 as the EOS token                                                 \n",
    "    sequences = Vector{Vector{Int}}()\n",
    "    for w in strings\n",
    "        s = Vector{Int}()\n",
    "        for c in collect(w)\n",
    "            if !haskey(tok2int,c)\n",
    "                push!(int2tok,c)\n",
    "                tok2int[c] = length(int2tok)\n",
    "            end\n",
    "            push!(s, tok2int[c])\n",
    "        end\n",
    "        push!(sequences, s)\n",
    "    end\n",
    "    return sequences\n",
    "end\n",
    "\n",
    "sequences = readdata();\n",
    "for x in (sequences, strings, int2tok, tok2int); println(summary(x)); end\n",
    "for x in strings[501:505]; println(x); end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"3736-element Array{Any,1}\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Minibatch sequences putting equal length sequences together:\n",
    "\n",
    "function minibatch(sequences, batchsize)\n",
    "    table = Dict{Int,Vector{Vector{Int}}}()\n",
    "    data = Any[]\n",
    "    for s in sequences\n",
    "        n = length(s)\n",
    "        nsequences = get!(table, n, Any[])\n",
    "        push!(nsequences, s)\n",
    "        if length(nsequences) == batchsize\n",
    "            push!(data, [[ nsequences[i][j] for i in 1:batchsize] for j in 1:n ])\n",
    "            empty!(nsequences)\n",
    "        end\n",
    "    end\n",
    "    return data\n",
    "end\n",
    "\n",
    "batchsize, statesize, vocabsize = 128, 128, length(int2tok)\n",
    "data = minibatch(sequences,batchsize)\n",
    "summary(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Dict{Symbol,Any} with 6 entries\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize model and optimization parameters\n",
    "model = opts = nothing; knetgc() # clean memory from previous run\n",
    "model = initmodel(statesize,vocabsize)\n",
    "opts = optimizers(model,Adam)\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 54.432871 seconds (81.08 M allocations: 5.394 GiB, 2.10% gc time)\n",
      "(1, 1.0333776f0)\n",
      " 53.261187 seconds (81.03 M allocations: 5.390 GiB, 2.14% gc time)\n",
      "(2, 0.10707488f0)\n",
      " 53.257308 seconds (81.00 M allocations: 5.390 GiB, 2.13% gc time)\n",
      "(3, 0.036991775f0)\n",
      " 53.199205 seconds (81.00 M allocations: 5.390 GiB, 2.13% gc time)\n",
      "(4, 0.020072017f0)\n",
      " 53.258049 seconds (81.00 M allocations: 5.390 GiB, 2.14% gc time)\n",
      "(5, 0.015270046f0)\n",
      " 53.219837 seconds (81.00 M allocations: 5.390 GiB, 2.16% gc time)\n",
      "(6, 0.0093233455f0)\n",
      " 53.109133 seconds (81.03 M allocations: 5.390 GiB, 2.16% gc time)\n",
      "(7, 0.0075012427f0)\n",
      " 52.973782 seconds (81.00 M allocations: 5.390 GiB, 2.14% gc time)\n",
      "(8, 0.006278418f0)\n",
      " 51.436275 seconds (81.00 M allocations: 5.390 GiB, 2.08% gc time)\n",
      "(9, 0.0051122336f0)\n",
      " 50.379791 seconds (81.00 M allocations: 5.390 GiB, 2.02% gc time)\n",
      "(10, 0.0037595273f0)\n",
      "528.532481 seconds (810.15 M allocations: 53.904 GiB, 2.12% gc time)\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "\n",
    "function train(model, data, opts)\n",
    "    sumloss = cntloss = 0\n",
    "    for sequence in data\n",
    "        grads,loss = s2sgrad(model, sequence, reverse(sequence))\n",
    "        update!(model, grads, opts)\n",
    "        sumloss += loss\n",
    "        cntloss += (1+length(sequence)) * length(sequence[1])\n",
    "    end\n",
    "    return sumloss/cntloss\n",
    "end\n",
    "\n",
    "@time for epoch=1:10\n",
    "    @time loss = train(model,data,opts) # ~1 min/epoch\n",
    "    println((epoch,loss))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"nrocirpac\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test on some examples:\n",
    "\n",
    "function translate(model, str)\n",
    "    state = model[:state0]\n",
    "    for c in collect(str)\n",
    "        input = onehotrows(tok2int[c], model[:embed1])\n",
    "        input = input * model[:embed1]\n",
    "        state = lstm(model[:encode], state, input)\n",
    "    end\n",
    "    input = eosmatrix(1, model[:embed2]) * model[:embed2]\n",
    "    output = Char[]\n",
    "    for i=1:100 #while true                                                                                                \n",
    "        state = lstm(model[:decode], state, input)\n",
    "        pred = predict(model[:output], state[1])\n",
    "        i = indmax(Array(pred))\n",
    "        i == 1 && break\n",
    "        push!(output, int2tok[i])\n",
    "        input = onehotrows(i, model[:embed2]) * model[:embed2]\n",
    "    end\n",
    "    String(output)\n",
    "end\n",
    "\n",
    "translate(model,\"capricorn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.1",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
